## 第三周周报

2020.10.23

报告人：何千越，其他组员：米唯实，安若鼎，张颖，杨恺

---

### 项目名称

Python实现下的含噪语音分割以及数字-说话人识别

---

### 当前项目所属阶段

- 双门限分割已经可以使用（从Matlab移植到Python），并且进行了自适应优化，但仍然存在提升空间
- 使用Keras搭建了神经网络，进行了MFCC特征的分类，正在优化网络结构
- 自主实现了FFT

---

### 本周工作情况

- 何千越：

  - 尝试维纳滤波与FIR，效果没有达到Kalman滤波的白噪声过滤程度。维纳滤波效果不好可能是对历史的初始估计存在问题。
  - 将张颖同学的Matlab双门限程序用Python进行实现，移植成功。加入了自适应起始端点移动（想法类似于退火算法，按照一个与步长相关的概率接受移动）以及结合了图像处理知识设计的最大方差分割（大津法阈值）优化后端点，过滤小幅度噪声。从结果上看更加准确鲁棒了。

- 米唯实：

  - 本周忙于雅思考试，任务4进度维持不变

- 张颖：

  - 实现了VAD算法代码的初步实现

  - 了解了语音信号自相关函数的求法，并比较观察了噪声和语音信号相关函数的差别，尝试利用自相

    关函数进行端点检测。

  - 初步了解DTW的流程及其DP算法的实现过程。

- 杨恺：

  - 了解熟悉了STFT,FFT算法，用代码成功将FFT频域抽取的算法实现
  - 写了特征提取函数函数，将语音信号全部转化为MFCC特征，将其用txt文件保存
  - 用Keras搭建了自己的网络模型，用提取好的MFCC特征当作输入，测试集准确率81%（过拟合情况比较严重）

- 安若鼎：
  - 了解动态时间规划的DTW算法
  - Matlab快速傅里叶变换算法的实现
  - 学习用python数据可视化

---

### 项目中遇到的问题

- 无论是Keras搭建的神经网络还是SVM（RBF）均存在较为严重的过拟合问题（准确率较高），首先仍然是没有使用双门限切割结果进行训练测试（**因为噪声以及错误分类存在，没有达到比较完美的水平**），手动分割的数据集自然较为准确

- 其次是双门限法本身。由于我们使用<u>**一长段音频（每段音频包括数十个相同的数字）**</u>进行双门限分割，本人给组员提的要求是尽量不使用固定阈值，对噪声进行估计，使用噪声动态调整门限。但由于：

  - 初始可能完全静音，没有一点噪声
  - 初始可能存在很强的噪声或是直接存在有效音频

  等原因，没办法对噪声进行鲁棒的估计。当前所使用的思想是：使用固定门限（较宽松的条件）粗提取有效段，再对每个有效段进行细致的处理（二次处理）。个人认为这个想法是自然的，直接双门限分割中，阈值需要对所有形式的音频（音量大、小 / 语速快、慢）进行折衷，这显然影响了门限准确度，而二次处理可以针对每一段可能的音频进行更加细致的处理。**<u>但！</u>**如何处理进行更加鲁棒的二次处理，这样的算法需要精细的构思。

---

### 下周工作计划

- 何千越：
  - VAD精细化二次处理，让其能以较高的准确率分割有效音频。若成功则将对所有组员再进行一次音频数据采集。
  - VAD加速与pyAudio实时输入研究。
- 米唯实：
  - 利用Kaldi尝试跑说话人识别
- 张颖：
  - 续改VAD算法
  - 了解FFT变换及MFCC系数提取的过程
- 杨恺：
  - 调节神经网络的框架，增加识别准确率（减小神经元个数与层数，增加卷积和池化层减小输入特征，增加正则化参数减小过拟合程度）
  - 计算每一个孤立字识别的准确率，寻找在MFCC特征中容易混淆的数字
- 安若鼎：
  - 尝试对DTW进行实现

---

### 附加说明

#### 自适应双门限优劣结果一览

​		红色为起始，蓝色为中止

![](C:\Users\15300\Desktop\whole_915.jpg)

<center> 图1. 较好的结果 </center>

![](C:\Users\15300\Desktop\whole_519.jpg)

<center> 图2. 较差的结果（杂分割） </center>

​		大多数分割结果都较好，但还不太够

- 其余内容见[Github AudioDSP项目](https://github.com/Enigmatisms/AudioDSP)





